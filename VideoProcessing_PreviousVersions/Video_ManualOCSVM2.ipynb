{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8Di0svJyyK3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.stats import kurtosis, weibull_min\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "zip_file_path = '/content/drive/MyDrive/test_images/trailer-.zip'\n",
        "destination_folder = '/content/drive/MyDrive/'\n",
        "\n",
        "!unzip -o -q \"{zip_file_path}\" -d \"{destination_folder}\"\n",
        "\n",
        "print(\"Unzipping completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YouPQVTE7qjT",
        "outputId": "3d83363f-571f-4b74-c333-102f0d5810b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def extract_keyframes(video_path, output_dir, motion_threshold=1.5, fps_sampling=5):\n",
        "    \"\"\"\n",
        "    Extract keyframes from a single video\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error opening video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_interval = frame_rate // fps_sampling\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Initialize variables\n",
        "    prev_frame = None\n",
        "    keyframe_index = 0\n",
        "    frame_index = 0\n",
        "\n",
        "    print(f\"Processing: {os.path.basename(video_path)}\")\n",
        "\n",
        "    while frame_index < total_frames:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect scene change\n",
        "        if prev_frame is not None:\n",
        "            diff = cv2.absdiff(prev_frame, gray_frame)\n",
        "            mean_diff = np.mean(diff)\n",
        "\n",
        "            if mean_diff > motion_threshold:\n",
        "                keyframe_path = os.path.join(output_dir, f'keyframe_{keyframe_index:04d}.jpg')\n",
        "                cv2.imwrite(keyframe_path, frame)\n",
        "                keyframe_index += 1\n",
        "\n",
        "        prev_frame = gray_frame\n",
        "        frame_index += frame_interval\n",
        "\n",
        "        # Print progress every 20%\n",
        "        if frame_index % (total_frames // 5) < frame_interval:\n",
        "            progress = (frame_index / total_frames) * 100\n",
        "            print(f\"Progress: {progress:.1f}%\")\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {keyframe_index} keyframes\")\n",
        "    return keyframe_index\n",
        "\n",
        "def process_video_lists(movie_list, trailer_list, base_output_dir='/content/drive/MyDrive/keyframes'):\n",
        "    \"\"\"\n",
        "    Process separate lists of movies and trailers\n",
        "    \"\"\"\n",
        "    # Create main output directories\n",
        "    movie_output_dir = os.path.join(base_output_dir, 'movies')\n",
        "    trailer_output_dir = os.path.join(base_output_dir, 'trailers')\n",
        "\n",
        "    print(\"\\nProcessing Movies:\")\n",
        "    print(\"-----------------\")\n",
        "    for movie_path in movie_list:\n",
        "        movie_name = os.path.splitext(os.path.basename(movie_path))[0]\n",
        "        movie_dir = os.path.join(movie_output_dir, movie_name)\n",
        "        extract_keyframes(movie_path, movie_dir)\n",
        "\n",
        "    print(\"\\nProcessing Trailers:\")\n",
        "    print(\"-------------------\")\n",
        "    for trailer_path in trailer_list:\n",
        "        trailer_name = os.path.splitext(os.path.basename(trailer_path))[0]\n",
        "        trailer_dir = os.path.join(trailer_output_dir, trailer_name)\n",
        "        extract_keyframes(trailer_path, trailer_dir)\n",
        "\n",
        "# Example usage\n",
        "movie_paths = [\n",
        "    '/content/drive/MyDrive/movie/BehindTheWalls.mp4',\n",
        "    '/content/drive/MyDrive/movie/HighWay.mp4',\n",
        "    '/content/drive/MyDrive/movie/NightVisit.mp4',\n",
        "    '/content/drive/MyDrive/movie/Stucco.mp4',\n",
        "    '/content/drive/MyDrive/movie/SushiNoh.mp4',\n",
        "    '/content/drive/MyDrive/movie/TheBottom.mp4',\n",
        "    '/content/drive/MyDrive/movie/TheChair.mp4',\n",
        "    '/content/drive/MyDrive/movie/UntilDeath.mp4'\n",
        "]\n",
        "\n",
        "trailer_paths = [\n",
        "    '/content/drive/MyDrive/trailer/BehindTheWallsT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/HighWayT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/NightVisitT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/StuccoT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/SushiNohT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/TheBottomT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/TheChairT.mp4',\n",
        "    '/content/drive/MyDrive/trailer/UntilDeathT.mp4'\n",
        "]\n",
        "\n",
        "# Process the videos\n",
        "process_video_lists(movie_paths, trailer_paths, 'keyframes')"
      ],
      "metadata": {
        "id": "EWjiEYuCsmEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb42a69-5d4c-4aa4-d42d-241d37f9171a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Movies:\n",
            "-----------------\n",
            "Processing: BehindTheWalls.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 2661 keyframes\n",
            "Processing: HighWay.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 2360 keyframes\n",
            "Processing: NightVisit.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 1805 keyframes\n",
            "Processing: Stucco.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 1734 keyframes\n",
            "Processing: SushiNoh.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 3180 keyframes\n",
            "Processing: TheBottom.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 2096 keyframes\n",
            "Processing: TheChair.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 3486 keyframes\n",
            "Processing: UntilDeath.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 4531 keyframes\n",
            "\n",
            "Processing Trailers:\n",
            "-------------------\n",
            "Processing: BehindTheWallsT.mp4\n",
            "Progress: 20.4%\n",
            "Progress: 40.2%\n",
            "Progress: 60.1%\n",
            "Progress: 79.9%\n",
            "Progress: 100.3%\n",
            "Extracted 112 keyframes\n",
            "Processing: HighWayT.mp4\n",
            "Progress: 20.2%\n",
            "Progress: 40.4%\n",
            "Progress: 60.0%\n",
            "Progress: 80.2%\n",
            "Progress: 99.9%\n",
            "Extracted 160 keyframes\n",
            "Processing: NightVisitT.mp4\n",
            "Progress: 20.1%\n",
            "Progress: 39.8%\n",
            "Progress: 60.0%\n",
            "Progress: 79.6%\n",
            "Progress: 99.8%\n",
            "Extracted 64 keyframes\n",
            "Processing: StuccoT.mp4\n",
            "Progress: 20.1%\n",
            "Progress: 40.1%\n",
            "Progress: 60.0%\n",
            "Progress: 79.9%\n",
            "Progress: 100.1%\n",
            "Extracted 124 keyframes\n",
            "Processing: SushiNohT.mp4\n",
            "Progress: 20.1%\n",
            "Progress: 40.0%\n",
            "Progress: 60.1%\n",
            "Progress: 80.0%\n",
            "Progress: 99.8%\n",
            "Extracted 177 keyframes\n",
            "Processing: TheBottomT.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 39.9%\n",
            "Progress: 59.9%\n",
            "Progress: 79.8%\n",
            "Progress: 99.8%\n",
            "Extracted 190 keyframes\n",
            "Processing: TheChairT.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 100.0%\n",
            "Extracted 463 keyframes\n",
            "Processing: UntilDeathT.mp4\n",
            "Progress: 20.0%\n",
            "Progress: 40.0%\n",
            "Progress: 60.0%\n",
            "Progress: 80.0%\n",
            "Progress: 99.9%\n",
            "Extracted 282 keyframes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM97Txi00p1D",
        "outputId": "d8233c33-073c-45f5-dd3f-2496b92dcb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.stats import kurtosis, weibull_min\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Path structure for movie and trailer keyframes\n",
        "movie_keyframes_dir = '/content/keyframes/movies'\n",
        "trailer_keyframes_dir = '/content/keyframes/trailers'"
      ],
      "metadata": {
        "id": "NWquFx-J14RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import kurtosis\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def calculate_kurtosis_safe(data):\n",
        "    \"\"\"Calculate kurtosis only if data has sufficient variance.\"\"\"\n",
        "    if np.std(data) < 1e-5:  # Avoid kurtosis calculation for low variance\n",
        "        return 0\n",
        "    return kurtosis(data, nan_policy='omit')\n",
        "\n",
        "def color_variance_in_luv(keyframes_dir):\n",
        "    variances = []\n",
        "    for root, _, files in os.walk(keyframes_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(root, filename))\n",
        "                luv_img = cv2.cvtColor(img, cv2.COLOR_BGR2Luv)\n",
        "                L_channel, u_channel, v_channel = cv2.split(luv_img)\n",
        "                cov_matrix = np.cov([L_channel.flatten(), u_channel.flatten(), v_channel.flatten()])\n",
        "                generalized_variance = np.linalg.det(cov_matrix)\n",
        "                variances.append(generalized_variance)\n",
        "    return np.mean(variances) if variances else np.nan\n",
        "\n",
        "def lighting_key_features(keyframes_dir):\n",
        "    brightness, shadows = [], []\n",
        "    shadow_threshold = 0.18\n",
        "    for root, _, files in os.walk(keyframes_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(root, filename))\n",
        "                luv_img = cv2.cvtColor(img, cv2.COLOR_BGR2Luv)\n",
        "                L_channel = luv_img[:, :, 0]\n",
        "                brightness.append(np.median(L_channel))\n",
        "                shadow_ratio = np.sum(L_channel < shadow_threshold * 255) / L_channel.size\n",
        "                shadows.append(shadow_ratio)\n",
        "    return np.mean(brightness), np.mean(shadows)\n",
        "\n",
        "def hsv_color_features(keyframes_dir):\n",
        "    h_means, s_means, v_means = [], [], []\n",
        "    h_vars, s_vars, v_vars = [], [], []\n",
        "    h_kurts, s_kurts, v_kurts = [], [], []\n",
        "    for root, _, files in os.walk(keyframes_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(root, filename))\n",
        "                hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "                H, S, V = cv2.split(hsv_img)\n",
        "\n",
        "                # Calculate means\n",
        "                h_means.append(np.mean(H))\n",
        "                s_means.append(np.mean(S))\n",
        "                v_means.append(np.mean(V))\n",
        "\n",
        "                # Calculate variances\n",
        "                h_vars.append(np.var(H))\n",
        "                s_vars.append(np.var(S))\n",
        "                v_vars.append(np.var(V))\n",
        "\n",
        "                # Calculate kurtosis safely\n",
        "                h_kurts.append(calculate_kurtosis_safe(H.flatten()))\n",
        "                s_kurts.append(calculate_kurtosis_safe(S.flatten()))\n",
        "                v_kurts.append(calculate_kurtosis_safe(V.flatten()))\n",
        "\n",
        "    return (np.mean(h_means), np.mean(s_means), np.mean(v_means),\n",
        "            np.mean(h_vars), np.mean(s_vars), np.mean(v_vars),\n",
        "            np.mean(h_kurts), np.mean(s_kurts), np.mean(v_kurts))\n",
        "\n",
        "def texture_analysis(keyframes_dir):\n",
        "    beta_params, gamma_params = [], []\n",
        "    for root, _, files in os.walk(keyframes_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(root, filename), cv2.IMREAD_GRAYSCALE)\n",
        "                hist, _ = np.histogram(img.flatten(), bins=256, density=True)\n",
        "                params = weibull_min.fit(hist, floc=0)\n",
        "                beta_params.append(params[0])\n",
        "                gamma_params.append(params[1])\n",
        "    return np.mean(beta_params), np.mean(gamma_params)\n",
        "\n",
        "def spatial_features(keyframes_dir, grid_size=3):\n",
        "    spatial_means, spatial_vars = [], []\n",
        "    for root, _, files in os.walk(keyframes_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(root, filename))\n",
        "                h, w, _ = img.shape\n",
        "                grid_h, grid_w = h // grid_size, w // grid_size\n",
        "                for i in range(grid_size):\n",
        "                    for j in range(grid_size):\n",
        "                        grid = img[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
        "                        spatial_means.append(np.mean(grid))\n",
        "                        spatial_vars.append(np.var(grid))\n",
        "    return np.mean(spatial_means), np.mean(spatial_vars)\n"
      ],
      "metadata": {
        "id": "cTojxgQv4DhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_features(keyframes_dir):\n",
        "    features = []\n",
        "    features.append(color_variance_in_luv(keyframes_dir))\n",
        "    features.extend(lighting_key_features(keyframes_dir))\n",
        "    features.extend(hsv_color_features(keyframes_dir))\n",
        "    features.extend(texture_analysis(keyframes_dir))\n",
        "    features.extend(spatial_features(keyframes_dir))\n",
        "    return features\n",
        "\n",
        "# Process features for movies and trailers separately\n",
        "def extract_features_for_dirs(keyframes_dirs):\n",
        "    features = []\n",
        "    for keyframes_dir in keyframes_dirs:\n",
        "        features.append(extract_all_features(keyframes_dir))\n",
        "    return np.array(features)\n"
      ],
      "metadata": {
        "id": "Tn_pc_Wv2HpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dirs = [os.path.join(movie_keyframes_dir, movie) for movie in os.listdir(movie_keyframes_dir)]\n",
        "trailer_dirs = [os.path.join(trailer_keyframes_dir, trailer) for trailer in os.listdir(trailer_keyframes_dir)]\n",
        "\n",
        "# Extract features\n",
        "movie_features = extract_features_for_dirs(movie_dirs)\n",
        "trailer_features = extract_features_for_dirs(trailer_dirs)"
      ],
      "metadata": {
        "id": "cszRBZYVy9te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "\n",
        "# Data preprocessing: impute and scale\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "scaler = RobustScaler()\n",
        "movie_features = scaler.fit_transform(imputer.fit_transform(movie_features))\n",
        "trailer_features = scaler.transform(imputer.transform(trailer_features))\n",
        "\n",
        "# Scoring function for One-Class SVM\n",
        "def ocsvm_score(estimator, X):\n",
        "    scores = estimator.decision_function(X)\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Manual hyperparameter tuning function for One-Class SVM\n",
        "def tune_svm_hyperparameters(X_scaled):\n",
        "    best_score = -np.inf\n",
        "    best_model = None\n",
        "\n",
        "    # Define parameter grid\n",
        "    nu_values = [0.01, 0.1, 0.5]\n",
        "    kernels = ['rbf', 'linear']\n",
        "    gamma_values = ['scale', 0.001, 0.01]\n",
        "\n",
        "    for nu in nu_values:\n",
        "        for kernel in kernels:\n",
        "            for gamma in gamma_values:\n",
        "                oc_svm = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)\n",
        "                oc_svm.fit(X_scaled)  # Fit model\n",
        "                score = ocsvm_score(oc_svm, X_scaled)  # Evaluate model\n",
        "\n",
        "                # Check if this is the best score so far\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_model = oc_svm\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Tune and train the One-Class SVM model manually on movie features\n",
        "oc_svm_model = tune_svm_hyperparameters(movie_features)\n",
        "\n",
        "# Save the model, scaler, and imputer\n",
        "joblib.dump(oc_svm_model, 'video2SVC1.pkl')\n",
        "joblib.dump(scaler, 'video2SVCScaler.pkl')\n",
        "joblib.dump(imputer, 'video2SVCImputer.pkl')\n",
        "\n",
        "print(\"Imputer, scaler, and One-Class SVM model saved after manual hyperparameter tuning.\")\n"
      ],
      "metadata": {
        "id": "gtP8aXIeb2x5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87fa8f00-5aba-4ba1-a5df-425bdab5f0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputer, scaler, and One-Class SVM model saved after manual hyperparameter tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Custom scoring function\n",
        "def ocsvm_score(estimator, X):\n",
        "    estimator.fit(X)\n",
        "    scores = estimator.decision_function(X)\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Hyperparameter tuning function\n",
        "def tune_svm_hyperparameters(X):\n",
        "    best_score = -np.inf\n",
        "    best_model = None\n",
        "    nu_values = [0.01, 0.1, 0.5]\n",
        "    kernels = ['rbf', 'linear']\n",
        "    gamma_values = ['scale', 0.001, 0.01]\n",
        "\n",
        "    for nu in nu_values:\n",
        "        for kernel in kernels:\n",
        "            for gamma in gamma_values:\n",
        "                oc_svm = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)\n",
        "                score = ocsvm_score(oc_svm, X)\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_model = oc_svm\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Stack movie and trailer features\n",
        "stacked_features = np.vstack((movie_features, trailer_features))\n",
        "\n",
        "# Impute and scale\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "scaler = RobustScaler()\n",
        "stacked_features = scaler.fit_transform(imputer.fit_transform(stacked_features))\n",
        "\n",
        "# Tune and train on the stacked features\n",
        "oc_svm_model = tune_svm_hyperparameters(stacked_features)\n",
        "\n",
        "# Save model, scaler, and imputer\n",
        "joblib.dump(oc_svm_model, 'video2SVC1_combined.pkl')\n",
        "joblib.dump(scaler, 'video2SVCScaler_combined.pkl')\n",
        "joblib.dump(imputer, 'video2SVCImputer_combined.pkl')\n",
        "\n",
        "print(\"Model, scaler, and imputer saved for stacked movie and trailer features.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4o4C810Ohnr",
        "outputId": "f671bdc4-45ca-4141-aae7-bebefc9fe7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, scaler, and imputer saved for stacked movie and trailer features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import shutil\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "best_oc_svm_model = joblib.load('/content/video2SVC1_combined.pkl')\n",
        "scaler = joblib.load('/content/video2SVCImputer_combined.pkl')\n",
        "imputer = joblib.load('/content/video2SVCImputer_combined.pkl')\n",
        "\n",
        "timestamps_df = pd.read_csv('/content/IgnoreITAudioCSV.csv')\n",
        "movie_file = '/content/ignoreIT.mp4'\n",
        "\n",
        "def extract_frames(movie_file, timestamps):\n",
        "    frames = []\n",
        "    video = cv2.VideoCapture(movie_file)\n",
        "\n",
        "    for _, row in timestamps.iterrows():\n",
        "        start_time = row['Start Time (s)']\n",
        "        video.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
        "        success, frame = video.read()\n",
        "        if success:\n",
        "            frames.append(frame)\n",
        "\n",
        "    video.release()\n",
        "    return frames\n",
        "\n",
        "def extract_all_features(keyframes_dir):\n",
        "    features = []\n",
        "    features.append(color_variance_in_luv(keyframes_dir))\n",
        "    features.extend(lighting_key_features(keyframes_dir))\n",
        "    features.extend(hsv_color_features(keyframes_dir))\n",
        "    features.extend(texture_analysis(keyframes_dir))\n",
        "    features.extend(spatial_features(keyframes_dir))\n",
        "    return features\n",
        "\n",
        "def extract_features_from_frame(frame):\n",
        "    temp_dir = 'temp_frame_dir'\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "    frame_path = os.path.join(temp_dir, 'frame.jpg')\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "    features = extract_all_features(temp_dir)\n",
        "    shutil.rmtree(temp_dir)\n",
        "    return features\n",
        "\n",
        "frames = extract_frames(movie_file, timestamps_df)\n",
        "\n",
        "X_new = np.array([extract_features_from_frame(frame) for frame in frames])\n",
        "\n",
        "if np.any(np.isnan(X_new)):\n",
        "    X_new_imputed = imputer.transform(X_new)\n",
        "else:\n",
        "    X_new_imputed = X_new\n",
        "X_new_scaled = scaler.transform(X_new_imputed)\n",
        "\n",
        "decision_scores = best_oc_svm_model.decision_function(X_new_scaled)\n",
        "print(decision_scores)\n",
        "threshold = -1 # Define your threshold here based on your model's expected score range\n",
        "\n",
        "trailer_worthy_indices = np.where(decision_scores > threshold)[0]\n",
        "\n",
        "timestamps_df['trailer_worthy'] = np.where(timestamps_df.index.isin(trailer_worthy_indices), 1, -1)\n",
        "\n",
        "trailer_worthy_df = timestamps_df[timestamps_df['trailer_worthy'] == 1]\n",
        "\n",
        "if not trailer_worthy_df.empty:\n",
        "    print(trailer_worthy_df)\n",
        "    trailer_worthy_df.to_csv('ignoreItTrailerV2.csv', index=False)\n",
        "else:\n",
        "    print(\"No trailer-worthy timestamps were found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0o2n5jvxAIi",
        "outputId": "0899ef47-50c5-4a6f-ecec-12346202b9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-11402.24467428  82018.16807601 107096.95059976 358232.94495827\n",
            " -12399.07085859 366704.06564731 108276.34173681   1214.41186298\n",
            " 371996.36381508 366138.60493097 262935.16151966  -9430.88552438\n",
            "  -3275.98471428 104138.61792512  -2306.86706166  73054.8533785\n",
            "  21444.57296186  40309.88350055  -4164.61268385  23232.67961618\n",
            "  54698.66927246  44015.83028886]\n",
            "    Start Time (s)  End Time (s)  trailer_worthy\n",
            "1               35            40               1\n",
            "2              135           140               1\n",
            "3              125           130               1\n",
            "5              130           135               1\n",
            "6              160           165               1\n",
            "7                5            10               1\n",
            "8              110           115               1\n",
            "9              155           160               1\n",
            "10             105           110               1\n",
            "13              45            50               1\n",
            "15              25            30               1\n",
            "16              10            15               1\n",
            "17              30            35               1\n",
            "19              15            20               1\n",
            "20              20            25               1\n",
            "21             185           190               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "import pandas as pd\n",
        "\n",
        "# Load timestamps from CSV\n",
        "csv_file_path = '/content/trailer_worthy_timestamps.csv'\n",
        "timestamps_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Load the movie file\n",
        "movie_file_path = '/content/drive/MyDrive/VideoMP4/bleep.mp4'\n",
        "movie = VideoFileClip(movie_file_path)\n",
        "\n",
        "# Initialize a list to hold video clips\n",
        "clips = []\n",
        "\n",
        "# Extract clips based on the timestamps\n",
        "for _, row in timestamps_df.iterrows():\n",
        "    start_time = row[\"Start Time (s)\"]\n",
        "    end_time = row[\"End Time (s)\"]\n",
        "\n",
        "    if not (start_time == 315 and end_time == 320):\n",
        "        clip = movie.subclip(start_time, end_time)\n",
        "        clips.append(clip)\n",
        "\n",
        "# Concatenate all clips into one final trailer\n",
        "final_trailer = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "# Write the final trailer to a file, ensuring audio is included\n",
        "output_path = \"bleep2.mp4\"\n",
        "final_trailer.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "print(f\"Trailer-worthy compilation saved as {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbQ0pSmPrfsO",
        "outputId": "78e5b107-759f-4bc4-a275-8cec79af8e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video bleep2.mp4.\n",
            "Moviepy - Writing video bleep2.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready bleep2.mp4\n",
            "Trailer-worthy compilation saved as bleep2.mp4\n"
          ]
        }
      ]
    }
  ]
}
